{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Load and preprocess IMDB dataset\n",
    "def load_and_preprocess_data(max_features=20000, maxlen=100):\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Build RNN model\n",
    "def build_model(max_features=20000, maxlen=100, embedding_dim=128, rnn_units=64):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(max_features, embedding_dim))\n",
    "    model.add(layers.SimpleRNN(rnn_units))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, x_train, y_train, x_test, y_test, batch_size=128, epochs=10):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(\"Test Loss:\", loss)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    max_features = 20000  # Maximum number of words in the vocabulary\n",
    "    maxlen = 100  # Maximum length of input sequences\n",
    "    embedding_dim = 128  # Dimension of the embedding layer\n",
    "    rnn_units = 64  # Dimension of the RNN layer\n",
    "\n",
    "    # Load and preprocess data\n",
    "    x_train, y_train, x_test, y_test = load_and_preprocess_data(max_features=max_features, maxlen=maxlen)\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(max_features=max_features, maxlen=maxlen, embedding_dim=embedding_dim, rnn_units=rnn_units)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, x_test, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
